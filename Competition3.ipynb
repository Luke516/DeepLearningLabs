{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2396906\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "NUM_PROGRAM = 8\n",
    "\n",
    "cut_programs = np.load('cut_Programs.npy')\n",
    "cut_questions = np.load('cut_Questions.npy')\n",
    "\n",
    "voc_dict = np.load('voc_dict.npy')\n",
    "\n",
    "#print(cut_programs[0][0])\n",
    "sentences = []\n",
    "tag = 0\n",
    "for program in cut_programs:\n",
    "    for episode in program:\n",
    "        for sentence in episode:\n",
    "            sentences.append(TaggedDocument(sentence, [tag]))\n",
    "            tag = tag+1\n",
    "            \n",
    "#print(sentences[:5])    \n",
    "print(len(sentences))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['媽給', '你', '送', '錢包', '來', '啦', ' ', '來', ' ', '你', '看', '一下', '是', '不', '是', '這個'], ['對', ' ', '就是', '這個', ' ', '你', '在', '哪裡', '找到', '它', '的'], []]\n",
      "['你', '看', ' ', '這是', '我', '新', '買', '的', '錢包']\n",
      "['我', '的', '錢包', '不見了', '啦']\n",
      "['以後', '上', '網咖', '的', '錢包', '在', '我', '身上']\n",
      "['什麼', '有', '錢包', '場']\n",
      "['早上', '你', '爸爸', '在', '車上', '找到', '的', ' ', '一定', '是', '前天', '你', '放學', '的', '時候', '掉', '在', '車上', '了']\n",
      "['我', '為什麼', '要給', '你們', '錢包']\n"
     ]
    }
   ],
   "source": [
    "print(cut_questions[0][0])\n",
    "\n",
    "# 6 optional reponses\n",
    "for i in range(1, 7):\n",
    "    print(cut_questions[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(sentences)\n",
    "%time model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00655633,  0.0018341 ,  0.00909029, -0.00417535,  0.00287022,\n",
       "       -0.00362734, -0.00428635, -0.00306576, -0.00326668, -0.00471139,\n",
       "        0.00798222,  0.00580871, -0.00925604,  0.00779096,  0.00577432,\n",
       "       -0.00578126,  0.00932818,  0.00676447, -0.00968587, -0.00824556,\n",
       "        0.00057338,  0.00264536, -0.00826198,  0.00461383,  0.0072657 ,\n",
       "        0.00798954,  0.0069545 , -0.00612866, -0.00465577, -0.00285655,\n",
       "       -0.00909406, -0.00694388,  0.00142866, -0.00563768,  0.00063792,\n",
       "       -0.00253888,  0.00361805, -0.00011609,  0.00840464, -0.00548477,\n",
       "       -0.00716005,  0.00137779,  0.0016199 , -0.00828679, -0.00062136,\n",
       "       -0.00482807,  0.00340087,  0.00994807,  0.00712933, -0.00318571],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['以後'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(sentences)):\n",
    "    inferred_vector = model.infer_vector(sentences[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (4): «當然 豐富 啦»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (3, 0.12613166868686676): «這次 的 收穫 真 豐富»\n",
      "\n",
      "SECOND-MOST (1, 0.04225558415055275): «昨天 晚上 的 流星雨»\n",
      "\n",
      "MEDIAN (0, -0.015214674174785614): «還好 天氣 不錯»\n",
      "\n",
      "LEAST (4, -0.22808095812797546): «當然 豐富 啦»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(sentences[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(sentences[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
